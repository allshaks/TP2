{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pylab as plt\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from random import choice, sample, shuffle\n",
    "from numpy.random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./Material_de_interes/tc02Data/yeast_LIT_Reguly.txt',\"r\")\n",
    "r = open('./Material_de_interes/tc02Data/yeast_LIT_RegulyBIS.txt',\"w\")\n",
    "lines=f.readlines()\n",
    "lista_red = []\n",
    "for linea in lines:\n",
    "    lista_red.append(linea.split('\\t')[:2])\n",
    "    \n",
    "for enlace in lista_red[1:]:\n",
    "    print('%s' %' '.join(enlace), file=r)\n",
    "f.close()\n",
    "r.close()\n",
    "red_lit2 = nx.read_edgelist('./Material_de_interes/tc02Data/yeast_LIT_RegulyBIS.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_lit = nx.read_edgelist('./Material_de_interes/tc02Data/yeast_LIT.txt')\n",
    "red_apms = nx.read_edgelist('./Material_de_interes/tc02Data/yeast_AP-MS.txt')\n",
    "red_bin = nx.read_edgelist('./Material_de_interes/tc02Data/yeast_Y2H.txt')\n",
    "red_lit2 = nx.read_edgelist('./Material_de_interes/tc02Data/yeast_LIT_RegulyBIS.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "esenciales = open('./Datos/Essential_ORFs_paperHe2.txt')\n",
    "lista_esenciales = []\n",
    "\n",
    "for line in esenciales:\n",
    "    lista_esenciales.append(line.rstrip('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nodos_esenciales(red, lista_atr = lista_esenciales, atributo = 'Esencial'):\n",
    "    \n",
    "    dict_vacio = dict()\n",
    "    nx.set_node_attributes(red, dict_vacio.fromkeys(list(red.nodes()),0), atributo )\n",
    "    \n",
    "    for nodo in lista_atr:\n",
    "        try:\n",
    "            red.nodes[nodo][atributo] = 1\n",
    "        except KeyError:\n",
    "            continue\n",
    "            \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodos_esenciales(red_lit)\n",
    "nodos_esenciales(red_bin)\n",
    "nodos_esenciales(red_apms)\n",
    "nodos_esenciales(red_lit2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nodosEsenciales(red, esenciales = lista_esenciales, atributo = 'Esencial'):\n",
    "    red_aux = red.copy()\n",
    "    red_aux.remove_nodes_from(list(nodosNoEsenciales(red).nodes()))\n",
    "    return red_aux.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nodosNoEsenciales(red, esenciales = lista_esenciales):\n",
    "    red_aux = red.copy()\n",
    "    red_aux.remove_nodes_from(esenciales)\n",
    "    return red_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sacarEsenciales(red):\n",
    "    red_aux = red.copy()\n",
    "    GC = max(nx.connected_component_subgraphs(red_aux), key=len)\n",
    "    n = GC.number_of_nodes()\n",
    "    red_aux.remove_nodes_from(list(nodosEsenciales(red)))\n",
    "    GC = max(nx.connected_component_subgraphs(red_aux), key=len)\n",
    "    m = GC.number_of_nodes()\n",
    "    return m/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.281121187139324"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sacarEsenciales(red_lit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleNodos(red,dic1,dic2,k,q,dif1=0):\n",
    "    if dif1 == 0:\n",
    "        dif1 = dic1[k][1]\n",
    "    try:\n",
    "        dif2 = dic1[q][0] - dif1\n",
    "        sample_nodos = sample(dic2[q],dif1)\n",
    "        red.remove_nodes_from(sample_nodos)\n",
    "        if dif2 <= 0:\n",
    "            return None\n",
    "        else:\n",
    "            sampleNodos(red,dic1,dic2,k,q-1,dif1=dif2)\n",
    "            \n",
    "    except:\n",
    "        sampleNodos(red,dic1,dic2,k,q-1,dif1=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remover_nodos_no_esenciales(red, indice, lista_grados, tot_remover, lista_no_esenciales_grado,\n",
    "                                prohibidos, removidos = 0):\n",
    "    \n",
    "    #prohibidos es una lista vacia en el primer caso\n",
    "    \n",
    "    grado = lista_grados[indice]\n",
    "    # miro los nodos no esenciales con ese grado\n",
    "    #nodos_grado = lista_no_esenciales_grado[grado]\n",
    "    n = len(lista_grados)\n",
    "    i = 0\n",
    "    while removidos < tot_remover:\n",
    "        m = len(lista_no_esenciales_grado[grado])\n",
    "        if m > 0:\n",
    "            \n",
    "            nodos_a_remover = np.random.choice(lista_no_esenciales_grado[grado], min(m, tot_remover - removidos),\n",
    "                                               replace = False)\n",
    "            # Filtro por las dudas\n",
    "            nodos = [nodo for nodo in nodos_a_remover if nodo not in prohibidos]\n",
    "            red.remove_nodes_from(nodos)\n",
    "            for nodo in nodos:\n",
    "                lista_no_esenciales_grado[grado].remove(nodo)\n",
    "            if len(nodos) == 0:\n",
    "                i += 1\n",
    "                lista_no_esenciales_grado[grado] = lista_no_esenciales_grado[lista_grados[min(indice+i,\n",
    "                                                                                          n-1)]] + lista_no_esenciales_grado[lista_grados[max(indice-i, 0)]]\n",
    "            removidos += len(nodos)\n",
    "            # Agrego los prohibidos a la lista de nodos\n",
    "            prohibidos = prohibidos + nodos\n",
    "            \n",
    "            #print('saco {}'.format(min(m, tot_remover, len(nodos))))\n",
    "            #print(lista_no_esenciales_grado[grado])\n",
    "            \n",
    "        else:\n",
    "            i += 1\n",
    "            lista_no_esenciales_grado[grado] = lista_no_esenciales_grado[lista_grados[min(indice+i, n-1)]] + lista_no_esenciales_grado[lista_grados[max(indice-i, 0)]]\n",
    "            #nodos = np.choice(lista_no_esenciales_grado[grado], min(m, tot_remover), replace = False)\n",
    "            #red.remove_node(nodo)\n",
    "            #lista_no_esenciales_grado[grado].remove(nodos)\n",
    "\n",
    "    # para un chequeo\n",
    "\n",
    "    # print('prohibi: {}'.format(len(prohibidos)))\n",
    "        \n",
    "    return red, lista_no_esenciales_grado, prohibidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomNoEsenciales(red, GC):\n",
    "    red_aux = red.copy()\n",
    "    n = red.number_of_nodes()\n",
    "    \n",
    "    #GC = max(nx.connected_component_subgraphs(red), key = len)\n",
    "    n_gc = GC.number_of_nodes()\n",
    "    \n",
    "    degs = sorted(dict(red.degree()).values(), reverse=True)\n",
    "    nodos = dict(red.nodes(data=True))\n",
    "    grados = {d: [0,0] for d in degs}\n",
    "    noEsencXGrado = defaultdict(list)\n",
    "    for nodo, deg in red.degree():\n",
    "        grados[deg][0] += nodos[nodo]['Esencial']\n",
    "        grados[deg][1] += 1-nodos[nodo]['Esencial']\n",
    "        if (not nodos[nodo]['Esencial']):\n",
    "            #print(nodos)\n",
    "            noEsencXGrado[deg].append(nodo)\n",
    "    grad = sorted(list(grados.keys()))\n",
    "    \n",
    "    # almacenamos las cantidades de nodos en el dataframe para que sea mas facil manipular\n",
    "    df_nodos = pd.DataFrame(grados).T\n",
    "    df_nodos.columns = ['esenciales', 'no esenciales']\n",
    "    df_nodos['diferencia'] = df_nodos['no esenciales'] - df_nodos['esenciales']   \n",
    "    \n",
    "    #list(df[df.esenciales>=1].index)\n",
    "    #print(grad)\n",
    "    #print(noEsencXGrado)\n",
    "    \n",
    "    diferencias = df_nodos.diferencia\n",
    "    \n",
    "    #print(df_nodos)\n",
    "    prohibidos = []\n",
    "    for grado, ind in zip(grad, range(len(grad))):\n",
    "        # Para ese grado, saco tantos nodos no esenciales como nodos esenciales hay con ese grado\n",
    "        # Cantidad de nodos a remover para un grado fijo\n",
    "        tot_es = df_nodos.loc[grado].esenciales\n",
    "        \n",
    "        #print(\"Total a sacar {}\".format(tot_es))\n",
    "        #print(\"Grado: {}, Indice: {}\".format(grad[ind],ind))\n",
    "        red_aux, noEsencXGrado, prohibidos = remover_nodos_no_esenciales(red_aux, ind, grad, tot_es,\n",
    "                                                                          noEsencXGrado, prohibidos)\n",
    "        #print(\"removidos {}\".format(removidos))\n",
    "        \n",
    "    GC_posterior = max(nx.connected_component_subgraphs(red_aux), key = len)\n",
    "    m = GC_posterior.number_of_nodes()\n",
    "    \n",
    "    return m/n_gc, grados, grad, df_nodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gc = max(nx.connected_component_subgraphs(red_apms), key = len)\n",
    "k, gr, acum, df = randomNoEsenciales(red_apms, gc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352.4165229797363\n"
     ]
    }
   ],
   "source": [
    "errores_apms = []\n",
    "gc = max(nx.connected_component_subgraphs(red_apms), key = len)\n",
    "start = time.time()\n",
    "for i in range(1000):\n",
    "    \n",
    "    gc_size, grados, gr, df = randomNoEsenciales(red_apms, gc)\n",
    "    errores_apms.append(gc_size)\n",
    "    \n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (np.mean(errores_apms), np.std(errores_apms), sacarEsenciales(red_apms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "errores_lit = []\n",
    "gc = max(nx.connected_component_subgraphs(red_lit), key = len)\n",
    "start = time.time()\n",
    "for i in range(1000):\n",
    "    \n",
    "    gc_size, grados, gr, df = randomNoEsenciales(red_lit, gc)\n",
    "    errores_lit.append(gc_size)\n",
    "    \n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = (np.mean(errores_lit), np.std(errores_lit), sacarEsenciales(red_lit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "errores_bin = []\n",
    "gc = max(nx.connected_component_subgraphs(red_bin), key = len)\n",
    "start = time.time()\n",
    "for i in range(1000):\n",
    "    gc_size, grados, gr, df = randomNoEsenciales(red_bin, gc)\n",
    "    errores_bin.append(gc_size)\n",
    "    \n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = (np.mean(errores_bin), np.std(errores_bin), sacarEsenciales(red_bin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328.57858633995056\n"
     ]
    }
   ],
   "source": [
    "errores_lit2 = []\n",
    "gc = max(nx.connected_component_subgraphs(red_lit2), key = len)\n",
    "start = time.time()\n",
    "for i in range(1000):\n",
    "    \n",
    "    gc_size, grados, gr, df = randomNoEsenciales(red_lit2, gc)\n",
    "    errores_lit2.append(gc_size)\n",
    "    \n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = (np.mean(errores_lit2), np.std(errores_lit2), sacarEsenciales(red_lit2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabla\n",
    "tabla3 = pd.DataFrame([a,b,c,d])\n",
    "tabla3.columns = ['Random no esenciales', 'Desvio', 'Esenciales']\n",
    "tabla3.index = ['APMS','Literatura','Y2H', 'Reguly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random no esenciales</th>\n",
       "      <th>Desvio</th>\n",
       "      <th>Esenciales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>APMS</th>\n",
       "      <td>0.379465</td>\n",
       "      <td>0.019438</td>\n",
       "      <td>0.323705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Literatura</th>\n",
       "      <td>0.417350</td>\n",
       "      <td>0.004811</td>\n",
       "      <td>0.281121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y2H</th>\n",
       "      <td>0.622151</td>\n",
       "      <td>0.011863</td>\n",
       "      <td>0.624165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reguly</th>\n",
       "      <td>0.540567</td>\n",
       "      <td>0.004132</td>\n",
       "      <td>0.575062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Random no esenciales    Desvio  Esenciales\n",
       "APMS                    0.379465  0.019438    0.323705\n",
       "Literatura              0.417350  0.004811    0.281121\n",
       "Y2H                     0.622151  0.011863    0.624165\n",
       "Reguly                  0.540567  0.004132    0.575062"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabla3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
